<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="ie=edge" />
    <title>CS 269 Final Project</title>
    <link rel="icon" href="./favicon.ico" type="image/x-icon" />
  </head>

  <body>
    <main>
      <h1>Classifying Wildfires in Satellite Imagery</h1>
      <h2>Connor Couture, Shirley Qi, Joseph Wong</h2>
      <p>
        As the impacts of climate change begin to be felt, wildfires have become
        a regular occurrence all over the world. With wildfires becoming more
        common, it is important to have an efficient and accurate way to
        identify the areas burned by wildfires. With satellite data widely
        available in today's world, there is now enough data to train a model to
        identify these areas. Using the Satellite Burned Area Dataset, we
        trained several models to identify areas from satellite images which
        have burn scars from recent wildfires. The UNet architecture
        (implemented in PyTorch) is one of the top models for medical image
        segmentation, so this was one of the models we decided to experiment on
        for this dataset. Some other models we explored on this dataset include
        a pre-trained version of Meta's Segment Anything model, and FastAI's
        UNet ResNet32 model implementation.
      </p>
      <h3>Images:</h3>
      <figure>
        <img src="./image.png" alt="image" style="width:512px">
        <figcaption>Fig.1 - Example post-burn image from the dataset.</figcaption>
      </figure>
      <figure>
        <img src="./true mask.png" alt="true" style="width:512px">
        <figcaption>Fig.2 - Mask associated with the satellite image. Purple = no burn, Yellow = burn</figcaption>
      </figure>
      <figure>
        <img src="./prediction.png" alt="image" style="width:512px">
        <figcaption>Fig.3 - UNet model's prediction of the burned areas</figcaption>
      </figure>
      <h3>Links:</h3>
      <ul>
        <li> Source code (note: dataset is required to run code and is only included in Google Drive. Model weights are also omitted here and can be found in Google): 
          <a
            href="https://drive.google.com/drive/folders/1QG-EPFF6ZquQdqQgPywNVHM6aVUx_UaR"
            >Google Drive</a
          >
          <a href="./Classifying Wildfires in Satellite Imagery">Folder with code</a>
        </li>
        <li><a href="./Classifying_Wildfires_in_Satellite_Imagery.pdf"> Report</a></li>
        <li><a href="https://drive.google.com/file/d/1LjFcHvbqU_clXdLaTGAvvJnD2VuNVFEX/view?usp=drive_link">Demo Video</a></li>
      </ul>
      <h3>Credits:</h3>
      <p>
        The dataset used is the
        <a href="https://zenodo.org/records/6597139"
          >Satellite Burned Area Dataset</a
        >, with source code for unpacking the data for training the model pulled
        from
        <a href="https://github.com/lccol/burned-area-baseline"
          >this GitHub repository</a
        >. We modified some of the code of loading the dataset to customize the
        dataset for our specific use-case. The UNet architecture was implemented
        in <a href="https://pytorch.org/">PyTorch</a> based on the UNet
        architecture described in
        <a href="https://arxiv.org/pdf/1505.04597">this paper</a>.
      </p>
      <p>
        The pretrained SAM model is from
        <a href="https://github.com/facebookresearch/segment-anything.git"
          >this GitHub repository</a
        >.
      </p>
    </main>
  </body>
</html>
